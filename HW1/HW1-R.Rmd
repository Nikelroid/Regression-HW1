---
title: "HW1-R"
author: "Nima Kelidari"
date: "2023-05-02"
output: html_document
---

```{r}
Sys.setlocale(locale = "persian")

?ggplot

#install.packages("data.table")
#install.packages("ggplot2")
#install.packages("tidyverse")
#install.packages("heatmaply")                                      
library(heatmaply)
library(data.table)
library(ggplot2)
library(tidyverse)
library(ggplot2)
mortality = fread("D:/Terme8/Regression/HW1/iranprovs_mortality_monthly.csv",encoding="UTF-8")

```

در این بخش، ابتدا چند کتابخانه نصب کرده و آن ها را ایمپورت میکنیم و داده ها را نیز وارد میکنیم.

```{r}

ggplotRegression <- function (fit) {
  
  require(ggplot2)
  
  ggplot(fit$model, aes_string(x = names(fit$model)[2], y = names(fit$model)[1])) + 
    geom_point() +
    stat_smooth(method = "lm", col = "red") +
    labs(title = paste("Adj R2 = ",signif(summary(fit)$adj.r.squared, 5),
                       "Intercept =",signif(fit$coef[[1]],5 ),
                       " Slope =",signif(fit$coef[[2]], 5),
                       " P =",signif(summary(fit)$coef[2,4], 5)))
}

```

این تابع را وقتی مینویسیم که بتوانیم شکل فیتی که انجام داده ایم برای مدل را به نمایش در بیاوریم.

```{r}

provs_per_mounth <- mortality %>% 
  group_by(y,prov,m) %>% 
  summarise(n = sum(n))

provs_per_year <- mortality %>% 
  group_by(y,prov) %>% 
  summarise(n = sum(n))

provs <- provs_per_year

normal <- c()
mort = mat<-matrix(list(), nrow=31, ncol=43,)
year_weights <- c(1,2,4,7,10,14,18,23,25)

```

در اینجا دو دیتا فریم که ردیف هایشان بر اساس سال و استان و ماه، و دیگری بر اساس سال و استان ادغام شده اند میسازیم و دو ماتریس و بردار خالی برای ذخیره داده ها در ادامه میسازیم.

```{r}

for(i in 1 : 31){
  #print(provs$prov[i])
  m <- provs_per_year %>%
    filter(prov %in% provs$prov[i])
  mm <- provs_per_mounth %>%
    filter(prov %in% provs$prov[i])
  earlier <- m %>%
    filter(y < 1398)
  fit <- earlier %>% 
    lm(n~y,data = .,weights = year_weights)
  normal <- c(normal,sum(earlier$n)/10000)
  for(j in 10 : 13){
    predict(fit,newdata = m)[j]
    predicted <- as.integer(predict(fit,newdata = m)[j])
    start <- j*12-11
    end <- j*12
    ex <- mm$n[start:end]-round(predicted/12)
    ex[ex<0] = 0
    ex <- ex[!is.na(ex)]
    start <- (j-10)*12 + 1
    end <- start + length(ex) -1
    mort[i,start:end]  <- ex
  }
}

mort <- matrix(as.numeric(mort), nrow=31, ncol=43,)
ggplotRegression(fit)
summary(fit)

```

یک تابع فیت شده از استان یزد در بالا رسم کرده ایم. کاری که در دو حلقه بالا انجام میدهیم، به این صورت است که با پیمایش روی استان ها، برای هر استان یک به یک روند تغییر میزان مرگ و میر ها از سال 89 تا 97 بررسی میکنیم و یک مدل خطی آموزش میدهیم. با اعمال سال 98 تا 1401 روی تابع، تعداد فوت شده های پیش بینی شده در صورت نبود کرونا را در این 4 سال به دست می آوریم. حال با کم کردن یک دوازدهم این مقدار (که تخمین ما از حدود مرگ و میر ها در هر ماه آن سال است) را از میزان مرگ و میر های کل کم کرده و ماکزیمم این مقدار با 0 را که مقدار فوت اضافه در ماه بخصوص واستان خاص است را در یک ماتریس 31 در 43 ذخیره میکنیم که به منزله 31 استان و 43 ماه مورد بررسی است. در انتها نیز ماتریس را عددی کرده و مدل فیت شده را رسم میکنیم. قابل توجه است که مدلی که فیت کردیم، سال ها وزن های متفاوتی دارند و سال های آخر تاثیر بیشتری در پیشبینی ما از آینده دارند. اینکار هم به این دلیل است که داده های پرت سال ها قبل تر تاثیر کمتری داشته باشند، هم انحراف در رشد جمعیتی که مشتق درجه دو آن منفی است اصلاح شود. حال با داشتن این ماتریس به سوال 1 تا 3 در ادامه پاسخ میدهیم.

```{r}

x <- c("98/1")
for (i in 2 : 43){
  x <- c(x,paste(98+floor(i/12),"/",i%%12+1))
}

p <- heatmaply(mort, 
               dendrogram = "none",
               xlab = "ماه", 
               ylab = "استان", 
               main = "نقشه فوت اضافه بر حسب استان",
               labCol = x,
               labRow = provs$prov[1:31],
               grid_color = "white",
               grid_width = 0.000001,
               
)
p

normalized <- mort / normal[row(mort)]

p <- heatmaply(normalized, 
               dendrogram = "none",
               xlab = "ماه", 
               ylab = "استان", 
               main = " نقشه فوت اضافه بر حسب استان (نرمال شده)",
               labCol = x,
               labRow = provs$prov[1:31],
               grid_color = "white",
               grid_width = 0.000001
)
p


```

در ابتدا، نام برای ستون های جدول نقشه حرارتی درست شده که اهمیت زیادی ندارد. سپس نقشه حرارتی از این ماتریس را رسم میکنیم. در اینجا یک مشکل وجود دارد، آن هم این است که همانطور که مشاهده میکنیم، تعداد فوت کرده ها شدیدا از هر استان به استان دیگر تفاوت دارد که متوجه میشویم به احتمال زیاد مربوط به تفاوت شدید جمعیت استان ها است. پس کل ماتریس را بر مرگ و میر از سال 89 تا 97 را که در مرحله قبلی برای هر استان ذخیره کرده بودیم تقسیم میکنیم و نقشه حرارتی نرمال شده را دوباره رسم میکنیم.
بخش اول

```{r}

print(paste("کل فوت شده های کشور:",sum(mort)))
      
```

بخش دوم

```{r}

print("کل فوت شده ها به تفکیک استان:")
for(i in 1:31){
  print(paste("تعداد فوت شده های استان",provs$prov[i],":",rowSums(mort)[i]))
}

      
```

بخش سوم

```{r}
rowSums(normalized)
```

این مجموع فاکتور های فوت هر استان است. تا حدی میتوانیم از این اعداد استفاده کنیم ولی استفاده نمیکنیم و از گروه های سنی استفاده میکنیم به این منظور.

```{r}

mort_age <- array(dim = c(31,21,43))


provs_per_mounth <- mortality %>% 
  group_by(y,prov,m,age_group) %>% 
  summarise(n = sum(n))

provs_per_year <- mortality %>% 
  group_by(y,prov,age_group) %>% 
  summarise(n = sum(n))

```

در اینجا، همان کار قبل را انجام میدهیم، با این تفاوت که دسته بندی را بر اساس گروه سنی نیز انجام میدهیم، به به جای یک ماتریس دو بعدی ذخیره سازی، یک آرایه 3 بعدی برای ذخیره سازی مدلسازی های هر سن داریم.

```{r}

for(k in 1 : 21){
  for(i in 1 : 31){
    #print(provs$prov[i])
    m <- provs_per_year %>%
      filter(age_group %in% provs_per_year$age_group[k]) %>% 
      filter(prov %in% provs$prov[i])
    
    mm <- provs_per_mounth %>%
      filter(age_group %in% provs_per_year$age_group[k]) %>% 
      filter(prov %in% provs$prov[i])
    earlier <- m %>%
      filter(y < 1398)
    fit <- earlier %>% 
      lm(n~y,data = .)
    for(j in 10 : 13){
      predict(fit,newdata = m)[j]
      predicted <- as.integer(predict(fit,newdata = m)[j])
      start <- j*12-11
      end <- j*12
      ex <- mm$n[start:end]-round(predicted/12)
      ex[ex<0] = 0
      ex <- ex[!is.na(ex)]
      ex <- ex/(sum(earlier$n)/10000)
      start <- (j-10)*12 + 1
      end <- start + length(ex) -1
      mort_age[i,k,start:end]  <- ex
    }
  }
  print(paste("محاسبات گروه سنی",provs_per_year$age_group[k],"پایان یافت"))
}

```

در اینجا دقیقا کار مشابه بخش اول انجام شد با این تفاوت که پیمایش روی سن ها هم انجام میشود و نتایج در آرایه سه بعدی ای که ساخته بودیم قرار میگیرند. به دلیل طولانی بودن اجرا، در انتها نیز یک نشانگر تعریف شده که نشان دهد محاسبات در چه مرحله ای قرار دارد.

```{r}

weights <- c(2,1,3,6,8,9,10,10,9,9,8,8,7,6,5,4,3,2,2,1,1)
weights <- weights / sum(weights)

factors <- matrix(ncol = 43,nrow=31)
for (i in 1 : 43){
  for (j in 1 : 31){
    factors[j,i] <- sum(mort_age[j,,i] * weights)
  }
}

```

سپس به سنین به صورتی که در بالا آمده وزن دهی میکینیم که نشان داده شود فوت گروه های مقاوم تر، به منزله بدتر عمل کردن است (پنالتی سن در نظر میگیریم) سپس حاصل ضرب داخلی هر سن را در ماه و استان بخصوص را حساب کرده و در یک ماتریس جدید میریزم.

```{r}

apply(factors,1,t.test)

overall <- rowSums(factors)

min_prove <- which.min(overall)
max_prove <- which.max(overall)

print(paste("استان با بهترین عملکرد، استان", provs$prov[min_prove],"است با", rowSums(mort)[min_prove],"فوت شده و فاکتور مرگ و میر",overall[min_prove]))
print(paste("استان با بدترین عملکرد، استان", provs$prov[max_prove],"است با", rowSums(mort)[max_prove],"فوت شده و فاکتور مرگ و میر",overall[max_prove]))


```

در انتها نیز سعی میکنیم در ابتدا تی تست را روی مقادیر حاصل شده اعمال کنیم که به ما نسبتا نتایج راضی کننده میدهد، در پایان هم با جمع سطر های ماتریس، یک فاکتور برای هر استان به دست می آوریم که به ما میگوید با توجه به سن، کدام استان ها بهترین و بدترین عملکرد را داشته و آن را خروجی میددهیم.
